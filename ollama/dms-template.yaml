version: "1"

# Template metadata
name: ollama
description: Ollama is a tool for running large language models locally, providing an easy way to deploy and interact with LLMs like Llama, Mistral, and more.
icon: https://ollama.com/public/ollama.png
category: ai
tags:
  - ai
  - llm
  - machine-learning
  - local-ai

# Supported versions
versions:
  - "latest"
  - "0.1.27"
defaultVersion: "latest"

# Service definitions
services:
  - name: ollama
    type: worker
    image: "ollama/ollama:${VERSION}"
    ports:
      - port: 11434
    env:
      - key: OLLAMA_HOST
        value: "0.0.0.0"
        description: Host address for Ollama API
      - key: OLLAMA_MODELS
        default: "/root/.ollama/models"
        configurable: true
        description: Path to store downloaded models
    volumes:
      - name: ollama-data
        path: /root/.ollama
        size: 51200
    health_check:
      type: http
      path: /
      port: 11434
      initial_delay: 30
      interval: 60
      timeout: 10
      retries: 3
    cpu: 1000
    memory: 4096
    tcp_exposure:
      enabled: false
      hostname: "${NAME}-${STAGE}.${DOMAIN}"
      port: 11434
      tls:
        mode: terminate
      gateway:
        name: dms-gateway
        namespace: dms-system
